from database.getDataFromDatabase import *
import streamlit as st
import pandas as pd
import plotly.express as px
import re
import wordcloud
from wordcloud import STOPWORDS, WordCloud
import matplotlib.pyplot as plt

st.set_page_config(
    page_title="Yelp Dashboard â€“ Analyse des avis",
    page_icon="ðŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("## ðŸ“ Analyse des Avis â€“ Table `review_table`")
st.markdown("---")

st.markdown("### ðŸŽ¯ Objectif")
st.markdown("Analyser les notes laissÃ©es par les utilisateurs pour comprendre les raisons rÃ©currentes des mauvaises Ã©valuations des entreprises.")

st.markdown("### ðŸ” Axes dâ€™analyse proposÃ©s")

# ðŸ”¸ Distribution des notes


# Affichage du titre et de l'explication
st.markdown("### â­ï¸ Distribution des notes (`stars`)")
st.markdown(
    "Visualiser la rÃ©partition des notes permet de dÃ©tecter un Ã©ventuel dÃ©sÃ©quilibre "
    "(ex : beaucoup de 1â˜… ou 2â˜…), ce qui peut indiquer une insatisfaction rÃ©currente."
)

# Chargement des donnÃ©es
with st.spinner("â³ Chargement de la distribution des notes..."):
    try:
        distribution = query_db("SELECT * FROM note_distribution_table;")
    except Exception as e:
        st.error("ðŸš« Impossible de charger les donnÃ©es depuis la base.")
        st.exception(e)
        distribution = None

# Affichage du graphique
if distribution is None or distribution.empty:
    st.info("ðŸ“­ Aucune donnÃ©e trouvÃ©e pour les notes. Veuillez vÃ©rifier la base.")
else:
    try:
        # Tri des Ã©toiles dans l'ordre croissant
        distribution = distribution.sort_values(by="stars")
        
        distribution = distribution.sort_values(by="stars")  # s'assurer que les Ã©toiles soient dans l'ordre
        st.bar_chart(distribution.set_index("stars")["nb_notes"])

        # RÃ©sumÃ© rapide
        total_avis = distribution['nb_notes'].sum()
        moyenne = round((distribution['stars'] * distribution['nb_notes']).sum() / total_avis, 2)

        st.markdown(f"ðŸ“Œ **Nombre total d'avis analysÃ©s :** `{total_avis}`")
        st.markdown(f"â­ï¸ **Note moyenne globale :** `{moyenne}` / 5")

    except Exception as e:
        st.error("âŒ Une erreur est survenue lors de la gÃ©nÃ©ration du graphique.")
        st.exception(e)


st.markdown("---")

# ðŸ”¸ Ã‰volution des notes dans le temps
st.markdown("#### ðŸ“† Ã‰volution des notes dans le temps (`date`)")
st.markdown(
    "Permet de dÃ©tecter des pÃ©riodes oÃ¹ la qualitÃ© a chutÃ© (ex : changement de personnel, incident, etc.)."
)
# ðŸ‘‰ METTRE UN GRAPHIQUE ICI (courbe dâ€™Ã©volution ou heatmap temporelle)

review_evolution = query_db("SELECT * FROM review_evolution_table;")

review_evolution["parsed_date"] = pd.to_datetime(review_evolution["parsed_date"])

fig = px.line(
    review_evolution,
    x="parsed_date",
    y="total_reviews",
    labels={"parsed_date": "Date", "total_reviews": "Nombre de reviews"},
    title="Ã‰volution des reviews dans le temps"
)

fig.update_layout(
    xaxis_title="Date",
    yaxis_title="Nombre de reviews",
    template="plotly_white",
    hovermode="x unified"
)

st.plotly_chart(fig, use_container_width=True)

review_evolution["cumulative_reviews"] = review_evolution["total_reviews"].cumsum()

fig_cum = px.line(
    review_evolution,
    x="parsed_date",
    y="cumulative_reviews",
    labels={"parsed_date": "Date", "cumulative_reviews": "Total cumulatif de reviews"},
    title="Croissance cumulative des reviews"
)

fig_cum.update_layout(
    xaxis_title="Date",
    yaxis_title="Total cumulatif de reviews",
    template="plotly_white",
    hovermode="x unified"
)

st.plotly_chart(fig_cum, use_container_width=True)


st.markdown("---")

# ðŸ”¸ Notes par utilitÃ©
st.markdown("#### ðŸ‘ Notes par utilitÃ© (`useful`)")
st.markdown(
    "Les avis jugÃ©s â€œutilesâ€ par d'autres utilisateurs sont souvent plus pertinents et mettent en Ã©vidence les vrais problÃ¨mes."
)
# ðŸ‘‰ METTRE UN GRAPHIQUE ICI (boxplot ou scatter plot entre `stars` et `useful`)

st.markdown("---")

# ðŸ”¸ Analyse des mots frÃ©quents dans les mauvaises notes
import re
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

st.markdown("### ðŸ—£ï¸ Mots les plus frÃ©quents dans les avis 1â˜… et 2â˜…")
st.markdown(
    """
    Les commentaires trÃ¨s nÃ©gatifs peuvent rÃ©vÃ©ler des problÃ¨mes rÃ©currents.  
    Cette analyse textuelle permet dâ€™identifier les **termes qui reviennent souvent dans les avis les plus critiques**.  
    > Exemples attendus : *attente*, *sale*, *cher*, *accueil*, etc.
    """
)

with st.spinner("ðŸ”Ž Analyse des avis en cours..."):
    try:
        review_df = query_db("SELECT text FROM review_table WHERE stars < 3;")
    except Exception as e:
        review_df = None
        st.error("âŒ Erreur lors du chargement des avis.")
        st.exception(e)

# Traitement sâ€™il y a des donnÃ©es
if review_df is None or review_df.empty:
    st.info("ðŸ“­ Aucun avis Ã  1â˜… ou 2â˜… disponible.")
else:
    try:
        # ConcatÃ©nation de tous les textes
        all_text = " ".join(review_df['text'].dropna().tolist()).lower()
        
        # Nettoyage du texte
        all_text = re.sub(r"[^a-zA-ZÃ€-Ã¿\s]", "", all_text)  # support accents
        all_text = re.sub(r"\s+", " ", all_text)  # supprime les espaces multiples
        
        # GÃ©nÃ©ration du nuage de mots
        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color='white',
            stopwords=STOPWORDS.union({"restaurant", "place", "food"}),  # mots frÃ©quents inutiles
            max_words=100,
            max_font_size=90,
            colormap="inferno",
            random_state=42
        ).generate(all_text)

        # Affichage du nuage
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig)

        st.caption("ðŸ”Ž *Ce nuage de mots permet de visualiser rapidement les motifs de mÃ©contentement les plus frÃ©quents.*")

    except Exception as e:
        st.error("âŒ Une erreur est survenue lors du traitement du texte.")
        st.exception(e)



st.markdown("---")

# ðŸ”¸ Notes par utilisateur

st.markdown("#### ðŸ‘¤ Notes donnÃ©es par les utilisateurs (`user_id`)")
st.markdown(
    """
    Certaines personnes ont tendance Ã  attribuer souvent de mauvaises notes (1â˜… ou 2â˜…), ce qui peut fausser lâ€™analyse globale.  
    Identifier ces profils permet de mieux comprendre sâ€™il sâ€™agit de cas isolÃ©s ou dâ€™un biais utilisateur.
    """
)

# Chargement des donnÃ©es depuis la table user_stats_table
with st.spinner("â³ Chargement des statistiques utilisateur..."):
    try:
        user_stats = query_db("SELECT * FROM user_table;")
    except Exception as e:
        user_stats = None
        st.error("âŒ Impossible de charger les donnÃ©es utilisateur.")
        st.exception(e)

# VÃ©rification des donnÃ©es
if user_stats is None or user_stats.empty:
    st.info("ðŸ“­ Aucune statistique utilisateur disponible.")
else:
    try:
        st.markdown("##### ðŸ“Š Distribution des moyennes de notes par utilisateur")

        fig, ax = plt.subplots(figsize=(10, 4))
        ax.hist(user_stats["avg_stars"], bins=30, color="#2C8F9B", edgecolor='black')
        ax.set_title("Distribution des moyennes de notes par utilisateur", fontsize=14)
        ax.set_xlabel("Note moyenne", fontsize=12)
        ax.set_ylabel("Nombre d'utilisateurs", fontsize=12)
        ax.grid(axis='y', linestyle='--', alpha=0.7)
        st.pyplot(fig)

        st.markdown("##### ðŸ” Exemple de profils dâ€™utilisateurs trÃ¨s sÃ©vÃ¨res")
        bad_raters = user_stats[user_stats["avg_stars"] < 2.5].sort_values(by="avg_stars")
        st.dataframe(bad_raters[["user_id", "avg_stars", "total_reviews"]].head(10))

    except Exception as e:
        st.error("ðŸš« Une erreur est survenue pendant l'affichage du graphique ou du tableau.")
        st.exception(e)

st.markdown("---")

# ðŸ§  SynthÃ¨se
st.markdown("### ðŸ§  SynthÃ¨se")
st.info(
    "ðŸ‘‰ Ces analyses permettent de dÃ©tecter des tendances gÃ©nÃ©rales et des points problÃ©matiques rÃ©currents dans les avis. Cela offre une base solide pour explorer les causes des mauvaises Ã©valuations."
)
